{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podobnostní metriky\n",
    "\n",
    "Tento notebook prezentuje různé metriky pro měření podobnosti mezi daty, včetně textových a numerických přístupů.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Levenshteinova vzdálenost\n",
    "\n",
    "Levenshteinova vzdálenost měří minimální počet operací (vložení, odstranění, náhrada), nutných k transformaci jednoho řetězce na druhý.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshteinova vzdálenost mezi \"kitten\" a \"sitting\" je 3\n"
     ]
    }
   ],
   "source": [
    "from textdistance import levenshtein\n",
    "\n",
    "str1 = \"kitten\"\n",
    "str2 = \"sitting\"\n",
    "\n",
    "lev_dist = levenshtein(str1, str2)\n",
    "print(f'Levenshteinova vzdálenost mezi \"{str1}\" a \"{str2}\" je {lev_dist}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Jaro-Winklerova podobnost\n",
    "\n",
    "Jaro-Winklerova metrika je užitečná zejména při porovnávání jmen a adres, protože přikládá vyšší váhu shodám na začátku řetězce.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaro-Winklerova podobnost mezi \"Robert\" a \"Rupert\" je 0.8000\n"
     ]
    }
   ],
   "source": [
    "from textdistance import jaro_winkler\n",
    "\n",
    "str1 = \"Robert\"\n",
    "str2 = \"Rupert\"\n",
    "\n",
    "similarity = jaro_winkler(str1, str2)\n",
    "print(f'Jaro-Winklerova podobnost mezi \"{str1}\" a \"{str2}\" je {similarity:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Kosinová podobnost\n",
    "\n",
    "Měří úhel mezi dvěma vektory reprezentujícími textové dokumenty nebo atributy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matice kosinové podobnosti:\n",
      "[[1.         0.29558668 0.29558668]\n",
      " [0.29558668 1.         0.08882283]\n",
      " [0.29558668 0.08882283 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "documents = [\n",
    "    \"Toto je první dokument.\",\n",
    "    \"Tento dokument je podobný prvnímu.\",\n",
    "    \"Toto je zcela jiný text.\",\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "cos_sim = cosine_similarity(tfidf_matrix)\n",
    "print(\"Matice kosinové podobnosti:\")\n",
    "print(cos_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Jaccardův koeficient\n",
    "\n",
    "Měří podobnost množin na základě jejich průniku a sjednocení.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccardův koeficient je 0.4286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "set1 = {1, 2, 3, 4, 5}\n",
    "set2 = {3, 4, 5, 6, 7}\n",
    "\n",
    "jaccard_index = len(set1.intersection(set2)) / len(set1.union(set2))\n",
    "print(f\"Jaccardův koeficient je {jaccard_index:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TF-IDF\n",
    "\n",
    "TF-IDF váží slova podle jejich četnosti v dokumentech a globální významnosti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF reprezentace dokumentů:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dokument</th>\n",
       "      <th>je</th>\n",
       "      <th>jiný</th>\n",
       "      <th>podobný</th>\n",
       "      <th>první</th>\n",
       "      <th>prvnímu</th>\n",
       "      <th>tento</th>\n",
       "      <th>text</th>\n",
       "      <th>toto</th>\n",
       "      <th>zcela</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.480458</td>\n",
       "      <td>0.373119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480458</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.383770</td>\n",
       "      <td>0.298032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298032</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.383770</td>\n",
       "      <td>0.504611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dokument        je      jiný   podobný     první   prvnímu     tento  \\\n",
       "0  0.480458  0.373119  0.000000  0.000000  0.631745  0.000000  0.000000   \n",
       "1  0.383770  0.298032  0.000000  0.504611  0.000000  0.504611  0.504611   \n",
       "2  0.000000  0.298032  0.504611  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       text      toto     zcela  \n",
       "0  0.000000  0.480458  0.000000  \n",
       "1  0.000000  0.000000  0.000000  \n",
       "2  0.504611  0.383770  0.504611  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(\"TF-IDF reprezentace dokumentů:\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Numerické metriky\n",
    "\n",
    "Euklidovská, Manhattanská a Mahalanobisova vzdálenost se využívají pro porovnávání číselných hodnot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euklidovská vzdálenost: 6.7082\n",
      "Manhattanská vzdálenost: 11.0000\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean, cityblock, mahalanobis\n",
    "import numpy as np\n",
    "\n",
    "point1 = np.array([2, 3, 5])\n",
    "point2 = np.array([7, 1, 9])\n",
    "\n",
    "euc_dist = euclidean(point1, point2)\n",
    "manh_dist = cityblock(point1, point2)\n",
    "\n",
    "print(f\"Euklidovská vzdálenost: {euc_dist:.4f}\")\n",
    "print(f\"Manhattanská vzdálenost: {manh_dist:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheap red apple', 'cheap apple', 'red apple low price', 'good deal red apple', 'green apple healthy', 'quality green apple great price']\n",
      "Possible duplicates:\n",
      " - Red apples at a low price\n",
      " - Quality green apples at a great price\n",
      " Similarity score: 0.30\n",
      "\n",
      "Possible duplicates:\n",
      " - Cheap red apples\n",
      " - Best deal on red apples\n",
      " Similarity score: 0.36\n",
      "\n",
      "Possible duplicates:\n",
      " - Cheap red apples\n",
      " - Cheap apples\n",
      " Similarity score: 0.80\n",
      "\n",
      "Possible duplicates:\n",
      " - Red apples at a low price\n",
      " - Best deal on red apples\n",
      " Similarity score: 0.27\n",
      "\n",
      "Possible duplicates:\n",
      " - Green apples are healthy\n",
      " - Quality green apples at a great price\n",
      " Similarity score: 0.34\n",
      "\n",
      "Possible duplicates:\n",
      " - Cheap red apples\n",
      " - Red apples at a low price\n",
      " Similarity score: 0.38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text.lower())  # Process text and convert to lowercase\n",
    "    lemmatized_words = [token.lemma_ for token in doc if not token.is_punct and not token.is_stop]\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "# List of documents, where some may be duplicates\n",
    "documents = [\n",
    "    \"Cheap red apples\",\n",
    "    \"Cheap apples\",\n",
    "    \"Red apples at a low price\",\n",
    "    \"Best deal on red apples\",\n",
    "    \"Green apples are healthy\",\n",
    "    \"Quality green apples at a great price\",\n",
    "]\n",
    "\n",
    "# Apply lemmatization to each document\n",
    "lemmatized_documents = [lemmatize_text(doc) for doc in documents]\n",
    "print(lemmatized_documents)\n",
    "\n",
    "# Convert texts to TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(lemmatized_documents)\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "cos_sim_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Define threshold for duplicate detection\n",
    "threshold = 0.2\n",
    "\n",
    "# Find similar documents\n",
    "duplicates = set()\n",
    "for i in range(len(documents)):\n",
    "    for j in range(i + 1, len(documents)):\n",
    "        if cos_sim_matrix[i, j] > threshold:\n",
    "            duplicates.add((documents[i], documents[j], cos_sim_matrix[i, j]))\n",
    "\n",
    "# Print detected duplicates\n",
    "for doc1, doc2, score in duplicates:\n",
    "    print(f\"Possible duplicates:\\n - {doc1}\\n - {doc2}\\n Similarity score: {score:.2f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
